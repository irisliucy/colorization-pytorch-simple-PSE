{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.misc\n",
    "from skimage import color\n",
    "import torch\n",
    "from IPython import embed\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "import model_rec as model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_norm = 1.\n",
    "l_cent = 50.\n",
    "ab_norm = 1.\n",
    "mask_cent = 0.\n",
    "mask_mult = 110.\n",
    "use_gpu = False\n",
    "H_proc, W_proc = (256,256) # resolution to process, needs to be multiple of 8\n",
    "\n",
    "def np2tens(in_np,use_gpu=True):\n",
    "\t# numpy HxWxC ==> Torch tensor 1xCxHxW\n",
    "\tout_tens = torch.Tensor(in_np.transpose((2,0,1)))[None,:,:,:]\n",
    "\tif(use_gpu):\n",
    "\t\tout_tens = out_tens.cuda()\n",
    "\telse:\n",
    "\t\tout_tens = out_tens.cpu()\n",
    "\treturn out_tens\n",
    "\n",
    "def tens2np(in_tens,use_gpu=True):\n",
    "\t# Torch tensor 1xCxHxW ==> numpy HxWxC\n",
    "\tif(use_gpu):\n",
    "\t\treturn in_tens.cpu().numpy().transpose((2,3,1,0))[:,:,:,0]\n",
    "\telse:\n",
    "\t\treturn in_tens.numpy().transpose((2,3,1,0))[:,:,:,0]\n",
    "\n",
    "def ind2sub(ind, H=256, W=256):\n",
    "    return (ind/H, ind - ind/H*H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** LOAD COLORIZER MODEL *****\n",
    "colorizer = model.SIGGRAPHGenerator()\n",
    "colorizer.load_state_dict(torch.load('./models/caffemodel_unnorm.pth'))\n",
    "colorizer.cuda() if(use_gpu) else colorizer.cpu()\n",
    "colorizer.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(in_ab, in_mask):\n",
    "    # normalize & center input ab, input mask\n",
    "    in_ab_norm = in_ab/ab_norm\n",
    "    in_mask_norm = (in_mask - mask_cent)*mask_mult\n",
    "\n",
    "    out_class, out_reg = colorizer.forward(np2tens(img_rs_l_norm,use_gpu=use_gpu), np2tens(in_ab_norm,use_gpu=use_gpu), np2tens(in_mask_norm,use_gpu=use_gpu))\n",
    "    out_class = out_class.data # 1 x AB x H_proc x W_proc, probability distribution at every spatial location (h,w) of possible colors\n",
    "    out_reg = out_reg.data # 1 x 2 x H_proc x W_proc\n",
    "\n",
    "    out_ab_norm = tens2np(out_reg)\n",
    "    out_ab = out_ab_norm*110 # un-normalize\n",
    "\n",
    "    # ***** CONCATENATE WITH INPUT *****\n",
    "    out_orig_ab = zoom(out_ab, (1.*H_orig/H_proc, 1.*W_orig/W_proc, 1) )\n",
    "\n",
    "    # concatenate with L channel, convert to RGB, save\n",
    "    out_orig_lab = np.concatenate((img_orig_l,out_orig_ab),axis=2)\n",
    "    out_orig_rgb = np.uint8(np.clip(color.lab2rgb(out_orig_lab),0,1)*255)\n",
    "\n",
    "    return (out_orig_rgb, out_class, out_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[477x636] Original resolution\n",
      "[256x256] Processed resolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizhang/anaconda2/lib/python2.7/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/Users/rizhang/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[388x648] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[884x586] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[841x561] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[428x629] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[788x523] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[479x720] Original resolution\n",
      "[256x256] Processed resolution\n",
      "[1024x791] Original resolution\n",
      "[256x256] Processed resolution\n"
     ]
    }
   ],
   "source": [
    "# ***** LOAD IMAGE, PREPARE DATA *****\n",
    "# for (ii,img_path) in enumerate(['image013.jpg','image015.jpg','image017.jpg','image019.jpg','image021.jpg','image023.jpg','IMG_0217.jpg','IMG_4818-1.jpg']):\n",
    "for (ii,img_path) in enumerate(['image013.jpg','image015.jpg','image017.jpg','image019.jpg','image021.jpg','image023.jpg','IMG_0217.jpg','IMG_4818-1.jpg']):\n",
    "    img_orig = cv2.imread('./imgs/%s'%img_path)[:,:,::-1]\n",
    "    (H_orig,W_orig) = img_orig.shape[:2]\n",
    "    print('[%ix%i] Original resolution'%(H_orig,W_orig))\n",
    "    print('[%ix%i] Processed resolution'%(H_proc,W_proc))\n",
    "\n",
    "    # take L channel at fullres\n",
    "    img_orig_lab = color.rgb2lab(img_orig)\n",
    "    img_orig_l = img_orig_lab[:,:,[0]]\n",
    "\n",
    "    # resize to processing size, take L channel for input\n",
    "    img_rs = cv2.resize(img_orig, (W_proc, H_proc), interpolation=cv2.INTER_CUBIC)\n",
    "    img_rs_lab = color.rgb2lab(img_rs)\n",
    "    img_rs_l_norm = (img_rs_lab[:,:,[0]]-l_cent)/l_norm # normalized\n",
    "\n",
    "    in_ab = np.zeros((H_proc, W_proc, 2)) # initialize blank ab input, mask\n",
    "    in_mask = np.zeros((H_proc, W_proc, 1))\n",
    "\n",
    "    (out_orig_rgb, out_class, out_reg) = run_model(in_ab, in_mask)\n",
    "\n",
    "    plt.imsave('out_%02d.jpg'%ii,out_orig_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
