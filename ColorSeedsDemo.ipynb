{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.misc\n",
    "from skimage import color\n",
    "import torch\n",
    "from IPython import embed\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import model_rec as model\n",
    "import model_rec_noupreshape as model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** CONSTANTS *****\n",
    "l_norm = 100.\n",
    "l_cent = 50.\n",
    "ab_norm = 110.\n",
    "mask_cent = 0.\n",
    "# mask_cent = .5\n",
    "mask_mult = 1.\n",
    "use_gpu = False\n",
    "H_proc, W_proc = (256,256) # resolution to process, needs to be multiple of 8\n",
    "\n",
    "# color bins for color classification and output recommendations\n",
    "A = 23 # the ab colormap is divided up into 23x23 color bins\n",
    "AB = A**2 # there are 23*23=529 color bins in total\n",
    "ab_step = 10 # spacing between discretized color bins\n",
    "ab_edge = ab_norm + ab_step/2\n",
    "a_range = np.arange(-ab_norm, ab_norm+ab_step, step=ab_step)\n",
    "bbs, aas = np.meshgrid(a_range, a_range)\n",
    "aas = aas.flatten()\n",
    "bbs = bbs.flatten()\n",
    "abs = np.concatenate((aas[:,None],bbs[:,None]),axis=1) # 529x2, list of discretized bin centers\n",
    "abs_norm = abs/ab_norm # 529x2, bin centers normalized from [-1, +1]\n",
    "MAX_ENTROPY = np.log(AB)\n",
    "\n",
    "K = 7 # number of recommendations from kmeans network\n",
    "\n",
    "# ***** HELPER FUNCTIONS *****\n",
    "def add_color_patch(in_ab,in_mask,ab=[0,0],hw=[128,128],P=5):\n",
    "\t# add a color patch\n",
    "\tin_ab[hw[0]:hw[0]+P,hw[1]:hw[1]+P,0] = ab[0]\n",
    "\tin_ab[hw[0]:hw[0]+P,hw[1]:hw[1]+P,1] = ab[1]\n",
    "\tin_mask[hw[0]:hw[0]+P,hw[1]:hw[1]+P,:] = 1.\n",
    "\treturn (in_ab,in_mask)\n",
    "\n",
    "def np2tens(in_np,use_gpu=True):\n",
    "\t# numpy HxWxC ==> Torch tensor 1xCxHxW\n",
    "\tout_tens = torch.Tensor(in_np.transpose((2,0,1)))[None,:,:,:]\n",
    "\tif(use_gpu):\n",
    "\t\tout_tens = out_tens.cuda()\n",
    "\telse:\n",
    "\t\tout_tens = out_tens.cpu()\n",
    "\treturn out_tens\n",
    "\n",
    "def tens2np(in_tens,use_gpu=True):\n",
    "\t# Torch tensor 1xCxHxW ==> numpy HxWxC\n",
    "\tif(use_gpu):\n",
    "\t\treturn in_tens.cpu().numpy().transpose((2,3,1,0))[:,:,:,0]\n",
    "\telse:\n",
    "\t\treturn in_tens.numpy().transpose((2,3,1,0))[:,:,:,0]\n",
    "\n",
    "def ind2sub(ind, H=64, W=64):\n",
    "    return (ind/H, ind - ind/H*H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorizer and color recommendation networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** LOAD COLORIZER MODEL *****\n",
    "colorizer = model.SIGGRAPHGenerator()\n",
    "# colorizer.load_state_dict(torch.load('./models/net_G_19_03_04_trained1ep.pth'))\n",
    "# colorizer.load_state_dict(torch.load('./models/caffemodel_mask01.pth'))\n",
    "colorizer.load_state_dict(torch.load('./models/caffemodel_mask01_rec.pth'))\n",
    "colorizer.cuda() if(use_gpu) else colorizer.cpu()\n",
    "colorizer.eval()\n",
    "\n",
    "# ***** COLOR RECOMMENDATION NETWORK *****\n",
    "# network converts probability distribution ==> K discrete recommendations\n",
    "recommender = model.KMeansGenerator(AB, K)\n",
    "recommender.load_state_dict(torch.load('./models/net_K_03_07.pth'))\n",
    "recommender.cuda() if use_gpu else recommender.cpu()\n",
    "recommender.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load image and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1583x1242] Original resolution\n",
      "[256x256] Processed resolution\n"
     ]
    }
   ],
   "source": [
    "# ***** LOAD IMAGE, PREPARE DATA *****\n",
    "img_orig = cv2.imread('./imgs/migrant_mother.jpg')[:,:,::-1]\n",
    "(H_orig,W_orig) = img_orig.shape[:2]\n",
    "print('[%ix%i] Original resolution'%(H_orig,W_orig))\n",
    "print('[%ix%i] Processed resolution'%(H_proc,W_proc))\n",
    "\n",
    "# take L channel at fullres\n",
    "img_orig_lab = color.rgb2lab(img_orig)\n",
    "img_orig_l = img_orig_lab[:,:,[0]]\n",
    "\n",
    "# resize to processing size, take L channel for input\n",
    "img_rs = cv2.resize(img_orig, (W_proc, H_proc), interpolation=cv2.INTER_CUBIC)\n",
    "img_rs_lab = color.rgb2lab(img_rs)\n",
    "img_rs_l_norm = (img_rs_lab[:,:,[0]]-l_cent)/l_norm # normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function for running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(in_ab, in_mask, verbose=False):\n",
    "    # normalize & center input ab, input mask\n",
    "    in_ab_norm = in_ab/ab_norm\n",
    "    in_mask_norm = (in_mask - mask_cent)*mask_mult\n",
    "\n",
    "    if(verbose):\n",
    "        print('L bounds: [%.3f,%.3f]'%(np.min(img_rs_l_norm).item(),np.max(img_rs_l_norm).item()))\n",
    "        print('ab bounds: [%.3f,%.3f]'%(np.min(in_ab_norm).item(),np.max(in_ab_norm).item()))\n",
    "        print('mask bounds: [%.3f,%.3f]'%(np.min(in_mask_norm).item(),np.max(in_mask_norm).item()))\n",
    "    out_class, out_reg = colorizer.forward(np2tens(img_rs_l_norm,use_gpu=use_gpu), np2tens(in_ab_norm,use_gpu=use_gpu), np2tens(in_mask_norm,use_gpu=use_gpu))\n",
    "    out_class = out_class.data # 1 x AB x H_proc x W_proc, probability distribution at every spatial location (h,w) of possible colors\n",
    "    out_reg = out_reg.data # 1 x 2 x H_proc x W_proc\n",
    "\n",
    "    out_ab_norm = tens2np(out_reg)\n",
    "    out_ab = out_ab_norm*ab_norm # un-normalize\n",
    "\n",
    "    # ***** CONCATENATE WITH INPUT *****\n",
    "    # resize output to original resolution\n",
    "    out_orig_ab = zoom(out_ab, (1.*H_orig/H_proc, 1.*W_orig/W_proc, 1) )\n",
    "\n",
    "    # concatenate with L channel, convert to RGB, save\n",
    "    out_orig_lab = np.concatenate((img_orig_l,out_orig_ab),axis=2)\n",
    "    out_orig_rgb = np.uint8(np.clip(color.lab2rgb(out_orig_lab),0,1)*255)\n",
    "    # cv2.imwrite('./imgs/migrant_mother/output_fullres.png',out_orig_rgb[:,:,::-1])\n",
    "\n",
    "    return (out_orig_rgb, out_class, out_reg)\n",
    "\n",
    "# ***** COMPUTE UNCERTAINTY *****\n",
    "def compute_entropy(out_class):\n",
    "    out_entropy = -torch.sum(out_class*torch.log(out_class),dim=1,keepdim=True)\n",
    "    out_entropy = out_entropy[0,0,:,:].data.numpy()\n",
    "\n",
    "    # grab least certain point\n",
    "    max_ind = np.argmax(out_entropy)\n",
    "    (max_h, max_w) = ind2sub(max_ind, H=out_entropy.shape[0], W=out_entropy.shape[1])\n",
    "\n",
    "    return(out_entropy, (max_h,max_w))\n",
    "\n",
    "def get_recommended_colors(out_class, (h,w)):\n",
    "    # capture the probability distribution at a single point\n",
    "    out_class_point = out_class[0,:,h,w] # 529, probability distribution over discretized space\n",
    "    in_point = img_rs_lab[h,w,0] # grayscale value\n",
    "\n",
    "    # use recommender network to get 7 discrete recommendations\n",
    "    reccs_ab = ab_norm*recommender(out_class_point[None,:,None,None]).reshape(K,2).data.cpu().numpy() # 7x2 list of colors in ab space\n",
    "\n",
    "    # convert recommended colors to RGB and display\n",
    "    reccs_lab = np.concatenate((in_point+np.zeros((K,1)),reccs_ab),axis=1)\n",
    "    reccs_rgb = color.lab2rgb(reccs_lab[None,:,:])\n",
    "\n",
    "    # recommender produces unordered points, compute an ordering based on probability distribution\n",
    "    dists = np.sum((reccs_ab[None,:,:] - abs[:,None,:])**2,axis=2) # for each of the 529 bins, compute distance to each of the recommended colors\n",
    "    inds = np.argmin(dists,axis=1) # for each of the 529 bins, figure out which recommended color is the closest\n",
    "    reccs_probs = np.array([np.sum(out_class_point.data.cpu().numpy()[inds==kk]) for kk in range(K)]) # probability of each of the recommended colors, should sum to 1\n",
    "    reccs_sorted_inds = np.argsort(reccs_probs)[::-1]\n",
    "    \n",
    "    reccs_ab = reccs_ab[reccs_sorted_inds,:]\n",
    "    reccs_probs = reccs_probs[reccs_sorted_inds]\n",
    "    reccs_rgb = reccs_rgb[:,reccs_sorted_inds,:]\n",
    "    \n",
    "    return (out_class_point.data.cpu().numpy(), reccs_rgb, reccs_ab, reccs_probs)\n",
    "\n",
    "# ***** REHEATING DISTRIBUTION *****\n",
    "def softmax(logits):\n",
    "    logits = logits-np.max(logits)\n",
    "    return np.exp(logits)/np.sum(np.exp(logits))\n",
    "\n",
    "def reheat_distribution(dist, T=.5):\n",
    "    return softmax(np.log(dist)/T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L bounds: [-0.500,0.500]\n",
      "ab bounds: [0.000,0.000]\n",
      "mask bounds: [0.000,0.000]\n",
      "[0] Adding ab=(10.0,60.0) to hw=(124,16)\n",
      "L bounds: [-0.500,0.500]\n",
      "ab bounds: [0.000,0.545]\n",
      "mask bounds: [0.000,1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizhang/anaconda2/lib/python2.7/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 7 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Adding ab=(10.0,40.0) to hw=(16,160)\n",
      "L bounds: [-0.500,0.500]\n",
      "ab bounds: [0.000,0.545]\n",
      "mask bounds: [0.000,1.000]\n",
      "[2] Adding ab=(10.0,40.0) to hw=(188,164)\n",
      "L bounds: [-0.500,0.500]\n",
      "ab bounds: [0.000,0.545]\n",
      "mask bounds: [0.000,1.000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rizhang/anaconda2/lib/python2.7/site-packages/skimage/color/colorconv.py:985: UserWarning: Color data out of range: Z < 0 in 10 pixels\n",
      "  warn('Color data out of range: Z < 0 in %s pixels' % invalid[0].size)\n"
     ]
    }
   ],
   "source": [
    "# ***** INITIALIZE COLOR INPUT POINTS *****\n",
    "in_ab = np.zeros((H_proc, W_proc, 2)) # initialize blank ab input, mask\n",
    "in_mask = np.zeros((H_proc, W_proc, 1))\n",
    "\n",
    "sample_color = 'rand' # choose from 'rand','max','mean'\n",
    "T = 0.25 # temperature if choosing 'rand'\n",
    "    # T-->0 is equivalent to 'max'\n",
    "    # T < 1 makes things closer to 'max'\n",
    "    # T = 1 draws from predicted distribution\n",
    "    # T > 1 makes distribution more random\n",
    "    # T-->inf is equivalent to choosing a random color\n",
    "\n",
    "NUM_POINTS = 4\n",
    "for nn in range(NUM_POINTS):\n",
    "    # Run model\n",
    "    (out_orig_rgb, out_class, out_reg) = run_model(in_ab, in_mask, verbose=True)\n",
    "    H_DS_FACTOR = out_reg.shape[2]/out_class.shape[2]\n",
    "    W_DS_FACTOR = out_reg.shape[3]/out_class.shape[3]\n",
    "    \n",
    "    # Compute entropy and most uncertain point\n",
    "    out_entropy,(max_h,max_w) = compute_entropy(out_class)\n",
    "    \n",
    "    # Get probability distribution for most uncertain point\n",
    "    out_class_point = out_class[0,:,max_h,max_w].data.cpu().numpy()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(16,4))\n",
    "    plt.subplot(1,5,1)\n",
    "    plt.imshow(in_mask*color.lab2rgb(np.concatenate((50+np.zeros((H_proc,W_proc,1)),in_ab),axis=2)))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,5,2)\n",
    "    plt.imshow(out_orig_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,5,3)\n",
    "    plt.imshow(out_entropy, clim=(0,MAX_ENTROPY), cmap='hot')\n",
    "    plt.plot(max_w, max_h, 'bx')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,5,4)\n",
    "    plt.imshow(out_class_point.reshape(A,A), cmap='hot', extent=[-ab_edge,ab_edge,ab_edge,-ab_edge])\n",
    "    plt.plot([-ab_edge,ab_edge],[0,0],'w--')\n",
    "    plt.plot([0,0],[-ab_edge,ab_edge],'w--')\n",
    "    plt.xlabel('b'); plt.ylabel('a');\n",
    "    plt.axis('off');        \n",
    "\n",
    "    # Determine next color to add\n",
    "    if(sample_color=='rand'): # Sample randomly from probability distribution and add\n",
    "        reheat_class_point = reheat_distribution(out_class_point,T=T)\n",
    "        rand_ind = np.random.choice(range(AB),size=1,p=reheat_class_point/np.sum(reheat_class_point))[0]\n",
    "        ab_next = abs[rand_ind,:]\n",
    "    elif(sample_color=='max'): # Simply grab the most likely color\n",
    "        max_ind = np.argmax(out_class_point)\n",
    "        ab_next = abs[max_ind,:]\n",
    "    elif(sample_color=='mean'): # Grab mean of distribution\n",
    "        ab_next = np.sum(abs*out_class_point[:,None],axis=0)\n",
    "        \n",
    "    # Add next color\n",
    "    print('[%i] Adding ab=(%.1f,%.1f) to hw=(%i,%i)'%(nn,ab_next[0],ab_next[1],max_h*H_DS_FACTOR,max_w*W_DS_FACTOR))\n",
    "    (in_ab, in_mask) = add_color_patch(in_ab, in_mask, ab=ab_next, hw=[max_h*H_DS_FACTOR,max_w*W_DS_FACTOR], P=5)\n",
    "\n",
    "    # Plot added color\n",
    "    plt.plot(ab_next[1],ab_next[0],'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_entropy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
